{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.under_sampling import OneSidedSelection, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/BankChurners.csv')\n",
    "list = ['Attrition_Flag', 'Total_Trans_Ct', 'Total_Trans_Amt', 'Total_Revolving_Bal', 'Total_Ct_Chng_Q4_Q1', 'Contacts_Count_12_mon', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Months_on_book']\n",
    "data = data[list]\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category : [0 1]\n",
      "classes : ['Attrited Customer' 'Existing Customer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "object_columns = data.select_dtypes('object').columns\n",
    "\n",
    "for i in object_columns:\n",
    "\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(data[i])\n",
    "    data[i] = lb.transform(data[i])\n",
    "    \n",
    "    print(f'category : {np.unique(data[i])}\\nclasses : {lb.classes_}\\n')\n",
    "\n",
    "input = data.iloc[:,1:]\n",
    "target = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier\n",
    "##### 설명 참고 : https://wooono.tistory.com/97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 : 0.9789309215598789\n",
      "best param :  {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection()\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_param_grid = {'n_estimators' : [100, 200],\n",
    "                'learning_rate' : [0.01, 0.05, 0.1],\n",
    "                'max_depth' : [3, 5, 7],\n",
    "                'gamma' : [0, 1, 2]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb, param_grid=xgb_param_grid, scoring='f1', verbose=0, n_jobs=1)\n",
    "xgb_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best f1 : {xgb_grid.best_score_}')\n",
    "print('best param : ', xgb_grid.best_params_)\n",
    "\n",
    "## 참고 : https://cjh34544.tistory.com/m/4\n",
    "## http://aispiration.com/model/model-python-xgboost-hyper.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 : 0.9431179489975416\n",
      "best param :  {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection()\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr_param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "                'penalty' : ['l1', 'l2']}\n",
    "\n",
    "lr_grid = GridSearchCV(lr, param_grid=lr_param_grid, scoring='f1', verbose=0, n_jobs=1)\n",
    "lr_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best f1 : {lr_grid.best_score_}')\n",
    "print('best param : ', lr_grid.best_params_)\n",
    "\n",
    "# 참고 : https://wikidocs.net/16594\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 : 0.9673945807176031\n",
      "best param :  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection()\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {'n_estimators' : [100, 200],\n",
    "                'max_depth' : [3, 5, 7],\n",
    "                'min_samples_leaf' : [8, 12, 16],\n",
    "                'min_samples_split' : [8, 16, 20]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, param_grid=rf_param_grid, scoring='f1', verbose=0, n_jobs=1)\n",
    "rf_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best f1 : {rf_grid.best_score_}')\n",
    "print('best param : ', rf_grid.best_params_)\n",
    "\n",
    "## 참고 : https://techblog-history-younghunjo1.tistory.com/102\n",
    "## https://jaaamj.tistory.com/35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757522640958223\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(x_train, y_train)\n",
    "pred = rf.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "print(f1)\n",
    "\n",
    "## 참고 : https://techblog-history-younghunjo1.tistory.com/102\n",
    "## https://jaaamj.tistory.com/35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 : 0.9681012545243822\n",
      "best param :  {'C': 10, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection()\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "svc_param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "                'gamma' : [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "svc_grid = GridSearchCV(svc, param_grid=svc_param_grid, scoring='f1', verbose=0, n_jobs=1)\n",
    "svc_grid.fit(x_train, y_train)\n",
    "\n",
    "print(f'best f1 : {svc_grid.best_score_}')\n",
    "print('best param : ', svc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier는 파라미터 조정이 성능에 크게 영향을 미치지 않는다는 말이 많아 일단 생략함\n",
    "##### https://velog.io/@jus6886/Catboost\n",
    "##### https://undeadkwandoll.tistory.com/61\n",
    "##### https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002698429\n",
    "#### CatBoost 설명\n",
    "##### https://dailyheumsi.tistory.com/136\n",
    "##### https://techblog-history-younghunjo1.tistory.com/199\n",
    "##### https://heeya-stupidbutstudying.tistory.com/43?category=950711\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792093704245973\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "cat = CatBoostClassifier(random_state=42, verbose=0)\n",
    "cat.fit(x_train, y_train)\n",
    "pred = cat.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lightGBM은 10000개 이하의 데이터에 overfitting하기 쉬워서 사용 x\n",
    "##### https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/\n",
    "##### https://mac-user-guide.tistory.com/79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n",
    "##### 코드 참고 : https://eunki.tistory.com/60\n",
    "##### https://nonmeyet.tistory.com/entry/Python-Voting-Classifiers%EB%8B%A4%EC%88%98%EA%B2%B0-%EB%B6%84%EB%A5%98%EC%9D%98-%EC%A0%95%EC%9D%98%EC%99%80-%EA%B5%AC%ED%98%84\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 4개 사용한 hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9639684106614018 recall : 0.9835197174808711, precision : 0.9737762237762237, f1 : 0.9786237188872621\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "svm = SVC(C=10, gamma=0.1)\n",
    "rf = RandomForestClassifier(verbose=0)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('svm', svm), ('rf', rf), ('cat', cat)], voting='hard')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 4개 사용한 soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9595261599210266 recall : 0.9846968805179518, precision : 0.9676113360323887, f1 : 0.9760793465577596\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "svm = SVC(C=10, gamma=0.1, probability=True)\n",
    "rf = RandomForestClassifier(verbose=0)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('svm', svm), ('rf', rf), ('cat', cat)], voting='soft')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 3개 사용한 hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9639684106614018 recall : 0.9858740435550324, precision : 0.9715777262180975, f1 : 0.978673678060181\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "lr = LogisticRegression(C=0.1, penalty='l2')\n",
    "rf = RandomForestClassifier(verbose=0)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('rf', rf), ('cat', cat)], voting='hard')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "roc = roc_auc_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 3개 사용한 soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9639684106614018 recall : 0.9864626250735727, precision : 0.9710312862108922, f1 : 0.9786861313868612\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "rf = RandomForestClassifier(verbose=0)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('rf', rf), ('cat', cat)], voting='soft')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "roc = roc_auc_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 2개 사용한 hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9649555774925962 recall : 0.9823425544437905, precision : 0.9760233918128655, f1 : 0.9791727779407452\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('cat', cat)], voting='hard')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 2개 사용한 soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9654491609081934 recall : 0.987051206592113, precision : 0.9721739130434782, f1 : 0.9795560747663551\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('cat', cat)], voting='soft')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 2개 사용한 soft voting (성능이 제일 좋은 catboost에 가중치를  조금 더 줬을 경우, 가중치 3이상은 결과 변화 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9659427443237907 recall : 0.9864626250735727, precision : 0.9732868757259001, f1 : 0.9798304589301373\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input, target, random_state=42, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n",
    "\n",
    "oss = OneSidedSelection(random_state=42)\n",
    "x_train, y_train = oss.fit_resample(x_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier(gamma=1, learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "model = VotingClassifier(estimators=[('xgb', xgb), ('cat', cat)], weights=[1, 2], voting='soft')\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "\n",
    "print('accuracy : {0} recall : {1}, precision : {2}, f1 : {3}'.format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가지표로 f1 score를 쓰는 이유\n",
    "##### https://towardsdatascience.com/read-this-before-using-roc-auc-as-a-metric-c84c2d5af621\n",
    "##### https://stackoverflow.com/questions/44172162/f1-score-vs-roc-auc\n",
    "##### https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting Model 비교\n",
    "##### https://medium.com/@divyagera2402/boosting-algorithms-adaboost-gradient-boosting-xgb-light-gbm-and-catboost-e7d2dbc4e4ca\n",
    "##### http://dmqm.korea.ac.kr/activity/seminar/323\n",
    "##### https://hyunlee103.tistory.com/25\n",
    "##### https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라벨인코딩 vs 원핫인코딩\n",
    "##### https://wyatt37.tistory.com/11\n",
    "##### https://hye-z.tistory.com/16?category=501972\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한 것요약\n",
    "##### 원핫인코딩은 차원을 늘려 과적합되기 쉽다. 물론 규제로 어느정도 커버할 수 있으나 트리계열에서는 해당 변수가 아예 제외되는 문제점을 가진다. 차원의 저주 등등\n",
    "##### catboost는 파라미터 수정을 하지 않아도 효과가 나쁘지 않다\n",
    "##### lightgbm은 데이터의 수가 너무 적어 사용할 수 없다\n",
    "##### ROC가 F1보다 불균형 데이터 셋에 대해 관대한? 경향이 있어서 불균형 데이터 셋에는 F1을 평가지표로 사용한다.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc0be73154618f58c692376fe46a96bfb7aea1860fce4c5a4dc26143c6655afc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
